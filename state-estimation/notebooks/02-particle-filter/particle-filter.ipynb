{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">\n",
    "<img src=\"../../assets/images/dtlogo.png\" alt=\"Duckietown\" width=\"50%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from IPython import display\n",
    "import cv2\n",
    "import copy\n",
    "from tqdm.contrib import tzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particle filter allows us to estimate the robot's state by tracking some set of likely states and updating these as we get new measurements. This is achieved using a set of particles, where each particle $i$ represents a hypothesis of the state state $x_t^i$ with its associated weight $w_t^i$. So for example, in the context of state estimation (e.g., localization), each particle represents how likely the robot is to be located at that particular state.\n",
    "\n",
    "The algorithm is as follows. First, we initialize the particle filter by sampling $M$ particles. Usually the initial set of particles can be sampled uniformly from the set of all possible states (i.e., uniform sampling). Given a control signal $u_t$, we move all the particles (i.e., the state associated with each particle) that we currently have following the motion model. After this, we take a measurement $z_t$ (which we can get from our sensor) and update the weights of each particle based on how likely we are to measure $z_t$ if we were at the corresponding state of each particle (e.g., $p(z_t | x_i)$). We then resample all the particles, not uniformly, but according to the weights of each particle (i.e., the ones with higher weights are more likely to be sampled). This means that the particles that have higher weights will be sampled more often, while the ones with low weights may not be sampled at all. There are different options to obtain the predicted (i.e., filtered) state. In this notebook, we will do the simplest approach by taking the mean of the resampled particles.\n",
    "\n",
    "We then repeat this process every time we have new $u_t$ and $z_t$. In practice, we may not know what $p(z_t|x_i)$ is, so we may need other ways to compute the particle weight. We will see this later in the implementation.\n",
    "\n",
    "The above algorithm is the basic algorithm for the particle filter. There are some associated challenges and different algorithm variations try to address these issues. For example, if we implement the above algorithm, the performance will be largely affected by the initial set of particles because during resampling step, we only sample particles from the set of initial particles. Thus, it is possible that we may not even have particles that are near the correct state. This problem is sometimes known as particle depletion. To help alleviate this problem, during resampling step, instead of sampling completely from the set of particles that we currently have according to their weights, we can sample a small percentage of particles randomly from the set of all possible particles. \n",
    "\n",
    "Let's take a look at a concrete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: estimating robot position with particle filter\n",
    "\n",
    "Consider a robot moving in a room without obstacles. The robot is equipped with two sensors to measure distance between the robot and the walls, which allows the robot to measure the location of the robot (i.e., $x$ and $y$ positions) in the room. For the sake of simplicity, assume that the sensors directly provide us with a noisy measurement of the $(x,y)$ location in the room.\n",
    "\n",
    "Say the state of the robot is its $x$ and $y$ position in the room, and the control inputs are the velocity in each direction $v_x$ and $v_y$. The robot is initialized at $(x,y) = (0,0)$, and moves by applying constant control inputs $v_x = v_y = 0.1$ for 100 time steps. At each time step, after applying a control signal, the robot can take a measurement using the sensors to have an idea where it currently is. \n",
    "\n",
    "We assume the motion model:\n",
    "\n",
    "$$\n",
    "x_t = x_{t-1} + u_t + w_t,\n",
    "$$\n",
    "\n",
    "where $w_t \\sim \\mathcal{N}([0, 0]^T,\\sigma_R\\mathcal{I}_2)$ ($\\mathcal{I}_2$ is the $2x2$ identity matrix). Note that, unlike the Kalman filter, there is no requirement that the model be linear or have noise that is either additive or Gaussian. We are defining things this way to keep things simple. \n",
    "\n",
    "Let's also assume that the manufacturer of the sensor told us something about the performance of the sensor. That the measurements have zero mean and standard deviation $\\sigma$. As a result the measurement model is:\n",
    "\n",
    "$$ \n",
    "z_t = x_t + n_t\n",
    "$$\n",
    "\n",
    "where $n_t \\sim \\mathcal{N}([0, 0]^T,\\sigma_Q\\mathcal{I}_2$). Again note that we do not require the model to be structured this way in a particle filter but we do this for simplicty here. \n",
    "\n",
    "We will use the particle filter to improve our estimate of where the robot is at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the problem\n",
    "\n",
    "To understand the problem, let us plot the ideal trajectory and some possible measurements that we would get using the available sensors according to their specifications. In real life, we can get sensor measurements from our sensors. But here, to simulate sensor measurements, we will take the ground truth state at every time step and add some Gaussian noise from $\\mathcal{N}(0, 0.5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = [x_pos, y_pos]\n",
    "num_data = 100 # this is the number of timesteps we will simulate for\n",
    "ground_truth_x = np.linspace(0, 10, num=num_data + 1)\n",
    "ground_truth_y = ground_truth_x.copy() # x = y\n",
    "    \n",
    "# Simulate sensor measurements\n",
    "measurement_noise_x_var = 0.5 # these are the \"ground truth\" measurement covariances\n",
    "measurement_noise_y_var = 0.5\n",
    "noise_x = np.random.normal(loc=0.0, scale=measurement_noise_x_var, size=num_data-1)\n",
    "noise_y = np.random.normal(loc=0.0, scale=measurement_noise_y_var, size=num_data-1)\n",
    "measurement_x = np.linspace(10 / num_data, 10, num=num_data-1) + noise_x\n",
    "measurement_y = np.linspace(10 / num_data, 10, num=num_data-1) + noise_y\n",
    "\n",
    "# Compare ground truth and measurements\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(ground_truth_x, ground_truth_y)\n",
    "plt.plot(measurement_x, measurement_y)\n",
    "plt.xlabel('x position')\n",
    "plt.ylabel('y position')\n",
    "plt.legend(['ground truth trajectory', 'localization measurements from noisy sensor'])\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is quite a lot of noise coming from the sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing particle filter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create a Particle class. Each particle should have a state and a weight. We also need a method for a particle to move given a control signal $u_t$ (i.e., predict step) and a method to update its own weight given a measurement $z_t$. We will also need a function later to sample a particle from a particle set while accounting for the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the covariances of our motion and measurement models (we can adjust these and see what happens)\n",
    "import random\n",
    "sigma_R = 0.01\n",
    "sigma_Q = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle():\n",
    "    def __init__(self, x, y, w):\n",
    "        self.state = np.array([x, y])\n",
    "        self.weight = w\n",
    "    \n",
    "    def predict(self, u_t):\n",
    "        # We need to sample the particle through the prediction function (will require sampling from the Gaussian)\n",
    "        # For example, you could use the function scipy.stats.multivariate_normal(...).pdf(...)  - see documentation online\n",
    "        self.state = self.state # TODO - update this line\n",
    "        \n",
    "    def update(self, z_t):\n",
    "        self.weight = 1 # TODO - update this line\n",
    "\n",
    "def sample_particle(particles):\n",
    "    # TODO write this function to sample a particle based on the weights\n",
    "    # You might need to normalize the weights to obtain a valid probabilty distribution function (i.e. the sum of the weights is 1)\n",
    "    return particles[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement the particle filter and run it for each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_particles = 100 # pick a number\n",
    "alpha = 0.95\n",
    "\n",
    "filtered_xs = []\n",
    "filtered_ys = []\n",
    "measurements = []\n",
    "particles_over_time = []\n",
    "\n",
    "# sample initial particles\n",
    "particles = []\n",
    "\n",
    "def initialize_particle():\n",
    "    x = np.random.uniform(0, 10)\n",
    "    y = np.random.uniform(0, 10)\n",
    "    w = 1\n",
    "    return Particle(x,y,w)\n",
    "\n",
    "for i in range(num_particles):\n",
    "    particles.append(initialize_particle())\n",
    "\n",
    "# we assume constant control signal in this particular example\n",
    "u_t = np.array([10./num_data, 10./num_data]) \n",
    "    \n",
    "# run particle filter for each time step\n",
    "for i in range(num_data):\n",
    "    \n",
    "    # given u_t, move all the particles following the motion model\n",
    "    for p in particles:\n",
    "        p.predict(u_t)\n",
    "    \n",
    "    # get measurement z_t (in real life, get this from our sensor instead)\n",
    "    measurement_noise_x = np.random.normal(loc=0.0, scale=measurement_noise_x_var)\n",
    "    measurement_noise_y = np.random.normal(loc=0.0, scale=measurement_noise_y_var)\n",
    "    measurement_x_new = ground_truth_x[i+1] + measurement_noise_x\n",
    "    measurement_y_new = ground_truth_x[i+1] + measurement_noise_y\n",
    "    z_t = np.array([measurement_x_new, measurement_y_new])\n",
    "    measurements.append([measurement_x_new, measurement_y_new])\n",
    "    \n",
    "    # given z_t, update particles' weights\n",
    "    for p in particles:\n",
    "        p.update(z_t)\n",
    "    \n",
    "    # store resampled particles so we can plot them later\n",
    "    particles_over_time.append(copy.deepcopy(particles))\n",
    "\n",
    "    \n",
    "    new_particles = []\n",
    "    for i in range(int(num_particles*alpha)):\n",
    "        new_particle = copy.deepcopy(sample_particle(particles))\n",
    "        new_particle.weight = 1\n",
    "        new_particles.append(new_particle)\n",
    "    for i in range(int(num_particles*(1-alpha))):\n",
    "        new_particles.append(initialize_particle())\n",
    "    \n",
    "    particles = new_particles\n",
    "        \n",
    "    \n",
    "        \n",
    "    # get state estimate by taking the mean of the resampled particles (excluding the randomly sampled ones)\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for p in particles[:int(num_particles)]:\n",
    "        xs.append(p.state[0])\n",
    "        ys.append(p.state[1])\n",
    "    estimated_x = np.mean(xs)\n",
    "    estimated_y = np.mean(ys)\n",
    "    \n",
    "    # store filtered state so we can plot them later\n",
    "    filtered_xs.append(estimated_x)\n",
    "    filtered_ys.append(estimated_y)\n",
    "    \n",
    "measurements = np.array(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how the particles evolve over time so we can get a sense on how particle filter works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.stack((ground_truth_x, ground_truth_y), axis=1)\n",
    "filtered_states = np.stack((filtered_xs, filtered_ys), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pop-up may appear with the text \"Widget require us to download supporting files from a 3rd party\". Click the button 'Enable Downloads'.\n",
    "\n",
    "plots = []\n",
    "\n",
    "t = 0\n",
    "for (set_of_ps, true_state, filtered_state, z_t) in tzip(particles_over_time, ground_truth[1:], filtered_states, measurements):\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(true_state[0], true_state[1], color='blue', s=75)\n",
    "    plt.scatter(filtered_state[0], filtered_state[1], color='green', s=75)\n",
    "    plt.scatter(z_t[0], z_t[1], color='orange', s=75)\n",
    "    \n",
    "    for p in set_of_ps:\n",
    "        plt.scatter(p.state[0], p.state[1], color='red', s=p.weight * 50)\n",
    "    plt.title('time=%d, true (x,y)=(%.2f, %.2f) \\n filtered (x,y)=(%.2f, %.2f)' \n",
    "              % (t+1, true_state[0], true_state[1], filtered_state[0], filtered_state[1]))\n",
    "    plt.xlabel('x position')\n",
    "    plt.ylabel('y position')\n",
    "    plt.xlim(0,15)\n",
    "    plt.ylim(0,15)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    blue_patch = patches.Patch(color='blue', label='true state')\n",
    "    red_patch = patches.Patch(color='red', label='weighted particles')\n",
    "    green_patch = patches.Patch(color='green', label='filtered state')\n",
    "    orange_patch = patches.Patch(color='orange', label='noisy measurement')\n",
    "    plt.legend(handles=[blue_patch, red_patch, green_patch, orange_patch], loc='upper left', fontsize=8)\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    plot_img = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    plot_img = plot_img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plots.append(plot_img)\n",
    "    t += 1\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in plots:\n",
    "    plt.figure(figsize=(14,14))\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    time.sleep(0.1)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if we want to save the plot animation as gif\n",
    "\n",
    "# import imageio\n",
    "# imageio.mimsave('pf.gif', plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the particles (i.e., red dots) that are closer to where the robot is (i.e., blue dot) are getting bigger over time (i.e., gain more weight) as the robot moves. Here, the state predicted by the particle filter is visualized as the green dot, while the sensor measurement is visualized as the orange dot.\n",
    "\n",
    "Notice that it takes some time for the particles to \"converge\" to the true state. This can be observed by looking at the poor performance at earlier time steps. This is because initially the particles were spawned randomly so it will not produce a good estimation until we have enough measurements. Let's plot the state estimation over time below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the results\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(ground_truth[:,0], ground_truth[:,1])\n",
    "plt.plot(measurements[:,0], measurements[:,1])\n",
    "plt.plot(filtered_states[:,0], filtered_states[:,1])\n",
    "plt.xlabel('x position')\n",
    "plt.ylabel('y position')\n",
    "plt.legend(['ground truth trajectory', 'noisy measurements', 'particle filter estimate'])\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter seems to work as the green lines is close to the $x=y$ line. What can we do to improve the performance even further?\n",
    "\n",
    "While having more particles corresponds to better approximation of the true distribution that we are trying to estimate, it makes computation to be more expensive, so this can be a limitation depending on the hardware used. \n",
    "\n",
    "You may want to experiment with the parameters such as the number of particles or the $\\alpha$ parameter to see if you can make things even better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
