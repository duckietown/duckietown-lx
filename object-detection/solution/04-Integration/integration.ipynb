{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "![](../images/dtlogo.png)\n",
    "\n",
    "# Object detection for robots\n",
    "\n",
    "## Integration\n",
    "\n",
    "Finally, we need to integrate our model with ROS. Editing the functions in this notebook will edit the object detection node found in `src/object_detection/src`.\n",
    "\n",
    "\n",
    "### Simulation ðŸ’»\n",
    "If you don't have a Jetson Nano Duckiebot, you can run this exercise locally with the simulator. This will run your code as a Pytorch model. This means that we rely on your host machine's CPU or GPU to run your model.\n",
    "\n",
    "### Hardware ðŸš™\n",
    "\n",
    "If you have a Jetson Nano Duckiebot, you can run this exercise on your Duckiebot. This will convert your model to a TensorRT model, and run it your Jetson Nano's GPU.\n",
    "\n",
    "### What we are doing in this notebook\n",
    "\n",
    "In both cases, we need to edit the ROS node to decide how we will use the detections.\n",
    "Should you call your model on every image from your camera? Only once every 4-5 frames, to preserve your CPU?\n",
    "You might also want to change your robot's behaviour depending on the size of the detection.\n",
    "If it is small, the object is probably far away, so there's no need to stop.\n",
    "\n",
    "To get started, input your information in the functions bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def DT_TOKEN():\n",
    "    # todo change this to your duckietown token\n",
    "    dt_token = \"dt1-3nT8KSoxVh4MdLnE1Bq2mTkhRpbR35G8mmbjExKF7zGm6g4-43dzqWFnWd8KBa1yev1g3UKnzVxZkkTbfYtfGWrfSxeihNZvYVNfNmnCBP28LeqDxL\"\n",
    "    return dt_token\n",
    "\n",
    "def MODEL_NAME():\n",
    "    # todo change this to your model's name that you used to upload it on google colab.\n",
    "    # if you didn't change it, it should be \"yolov5\"\n",
    "    return \"yolov5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can use `dts exercises build` and `dts exercises test` (either with `--sim` for in simulation or with `-b DUCKIEBOT_NAME` for the real Duckiebot) to see it in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Framerate\n",
    "\n",
    "While object detection is useful, it is also very expensive, computationally.\n",
    "\n",
    "One trick used to reduce said cost is to only call the full model infrequently.\n",
    "For example, one might call the model only a few times a second, which is very slow in\n",
    "computer timeframes, but relatively fast for the real world. \n",
    "\n",
    "Of course, this varies from application to application. In very dynamic, fast\n",
    "robotic environments, clearly the model should be called more frequently.\n",
    "\n",
    "You can fine-tune this yourself: the function bellow indicates the number of frames\n",
    "your robot should skip before calling its object detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def NUMBER_FRAMES_SKIPPED():\n",
    "    # todo change this number to drop more frames\n",
    "    # (must be a positive integer)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In real life, we would use a full neural network model to produce very accurate\n",
    "predictions, and then a less accurate model coupled with a Kalman filter (or\n",
    "other such estimation system) to \"track\" each prediction during the skipped frames.\n",
    "\n",
    "For this exercises, we will limit ourselves to just skipping frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Some of your predictions might not actually be useful. For example, in Duckietown,\n",
    "the trucks and busses are always parked on the side of the road. Your robot will\n",
    "never have to avoid or stop for them.\n",
    "\n",
    "Cones can be in the road in some maps, but for this exercises, you can assume that there\n",
    "aren't any.\n",
    "\n",
    "#### Filtering by class\n",
    "\n",
    "For this reason, you probably want to remove all non-duckies from your predictions,\n",
    "since only duckies will be on the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# `class` is the class of a prediction\n",
    "def filter_by_classes(clas):\n",
    "    # Right now, this returns True for every object's class\n",
    "    # Change this to only return True for duckies!\n",
    "    # In other words, returning False means that this prediction is ignored.\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Filtering by score\n",
    "\n",
    "Depending on the model, you might also want to remove very unconfident detections.\n",
    "\n",
    "Then again, your model might not be confident even for detections that are absolutely\n",
    "correct. You should experiment to find a value that works well for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# `scor` is the confidence score of a prediction\n",
    "def filter_by_scores(scor):\n",
    "    # Right now, this returns True for every object's confidence\n",
    "    # Change this to filter the scores, or not at all\n",
    "    # (returning True for all of them might be the right thing to do!)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Filtering by bounding box\n",
    "\n",
    "Finally, you should also evaluate what each detection *means* in terms of positionning.\n",
    "\n",
    "If a bounding box is in the leftmost or rightmost thirds of the image, it might be the case that\n",
    "the object in not even on the road, and that your robot would be able to go by it without issue.\n",
    "\n",
    "![image of a bounding box](../images/thirds.png)\n",
    "\n",
    "Also, if a bounding box's area is small, its object is likely far away. So there is no need to\n",
    "try to avoid the object or stop the robot: the robot still has a bit of driving to do before it reaches\n",
    "the object. So filtering out small detections might be a good idea too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# `bbox` is the bounding box of a prediction, in xyxy format\n",
    "# So it is of the shape (leftmost x pixel, topmost y pixel, rightmost x pixel, bottommost y pixel)\n",
    "def filter_by_bboxes(bbox):\n",
    "    # Like in the other cases, return False if the bbox should not be considered.\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Fine-tuning\n",
    "\n",
    "In all of the functions above, there is not objective right answer. You should play with\n",
    "your functions and fine-tune their behaviours. Robotics is an iterative process!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "As mentioned, you can test the behavior of your agent in the simulator with \n",
    "\n",
    "    $ dts exercises test --sim\n",
    "\n",
    "Note that you will need to open the Image Viewer, and then the keyboard control joystick. Once the joystick is up and running, press \"a\" on it to enable automatic lane following.\n",
    "\n",
    "You can test on real hardware with\n",
    "\n",
    "    $ dts exercises test -b ![DUCKIEBOT_NAME]\n",
    "   \n",
    "In the case of the real hardware, you will need to be patient. Because of RAM limitations on the Jetson, we need to turn the camera off, then load your model, and then restart the camera. As soon as your model is loaded your robot might start moving! So make sure it is in a safe space. \n",
    "\n",
    "## Debugging\n",
    "\n",
    "After you run `dts exercises test` (either sim or on hardware) you can open the [VNC browser](http://localhost:8087/) to see what is happening. If you click on the `RQT Image View` icon and then in the dropdown select `/![DUCKIEBOT_NAME]/object_detection_node/object_detections_img`. This shows an image with your detections overlayed as shown below:\n",
    "\n",
    "![](../images/rqt_with_duckie.png)\n",
    "\n",
    "\n",
    "# Submission\n",
    "\n",
    "You can test your agent locally with\n",
    "\n",
    "    $ dts challenges evaluate\n",
    "    \n",
    "\n",
    "And then finally submit with \n",
    "\n",
    "    $ dts challenges submit\n",
    "    \n",
    "\n",
    "And then check out how you did [on the leaderboard](https://challenges.duckietown.org/v4/humans/challenges/mooc-objdet/leaderboard). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}