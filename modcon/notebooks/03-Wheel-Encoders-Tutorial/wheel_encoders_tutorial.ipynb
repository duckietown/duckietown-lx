{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">\n",
    "<img src=\"../../assets/images/dtlogo.png\" alt=\"Duckietown\" width=\"50%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ðŸš™ ðŸ’» 03 - Wheel encoders tutorial\n",
    "\n",
    "Encoders are sensors that convert (analog) angular position, or motion of a shaft, into a digital signal. \n",
    "\n",
    "In Duckietown we use Hall effect encoders [link to Wikipedia](https://en.wikipedia.org/wiki/Hall-effect_sensor), which extract the _incremental_ change in angular position of the wheels. Every time the shaft rotates of a certain set angle, i.e., the resolution of the encoder, it emits a pulse. We call these pulses \"ticks\".  \n",
    "\n",
    "We can use ticks from both wheels to measure the variation of the position of the Duckiebot while it moves. \n",
    "\n",
    "In this activity we learn how to access the data coming from the wheel encoders of our Duckiebot (whether physical or simulated), and understand what each field means. We will use this data for later activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš™ ðŸ’» Obtaining wheel encoder measurements. \n",
    "\n",
    "Let's look at the raw data that the wheel encoders produce. \n",
    "\n",
    "### ðŸ’» Read data from wheel encoders (simulation)\n",
    "\n",
    "To observe the wheel encoder data in simulation:\n",
    "\n",
    "1. Open a terminal on your computer, navigate to the directory containing this exercise, and type:\n",
    "\n",
    "       dts code build\n",
    "\n",
    "followed by:\n",
    "       \n",
    "    dts code workbench --sim\n",
    "\n",
    "You can then scroll up in the terminal and find the localhost address of VNC and paste in your browser as you did in the previous notebook.\n",
    "\n",
    "\n",
    "2. Connect to VNC, open RQT image view (icon on the desktop), and select compressed image topic from the top left dropdown menu\n",
    "    \n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/03-wheel-encoders/VNC-rqt-select-topic.png\" width=\"500\" alt=\"rqt-image-view\"></p>\n",
    "\n",
    "You should see what your simulated Duckiebot sees.\n",
    "        \n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/03-wheel-encoders/VNC-rqt-image-view.png\" width=\"500\" alt=\"db-pov\"></p>\n",
    "        \n",
    "2. Open LX terminal inside VNC, and type:\n",
    "\n",
    "       rostopic list\n",
    "\n",
    "to see the list of topics inside the agent. \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/03-wheel-encoders/VNC-rostopiclist.png\" width=\"500\" alt=\"rostopic-list\"></p> \n",
    "\n",
    "You can immagine a ROS topic as a \"pipe\" that is designed to allow messages of specific types to pass through. Messages carry the data we are interested about. \n",
    "\n",
    "3. To see the wheel encoder message of, for example, the left wheel, type: \n",
    "\n",
    "       rostopic echo /agent/left_wheel_encoder_node/tick\n",
    "\n",
    "Now open the virtual joystick inside VNC (doube-click on the icon on the desktop) and start pressing your keyboard arrows to move. \n",
    "\n",
    "While you're driving, you can optionally see a birds-eye view by opening the other localhost address provided in the terminal from where you launched `dts exercises test --sim`, i.e., `http://localhost:8090/`. \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/03-wheel-encoders/driving-bev.png\" width=\"500\" alt=\"rostopic-list\"></p> \n",
    "\n",
    "You will start seeing images moving (don't crash on a tree or you will have to restart!) and wheel encoder messages streaming on your terminal.\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/03-wheel-encoders/VNC-encoder-tick.png\" width=\"400\" alt=\"rostopic-list\"></p>    \n",
    "\n",
    "Messages will look like this:\n",
    "\n",
    "```    \n",
    "---\n",
    "header: \n",
    "  seq: 372\n",
    "  stamp: \n",
    "    secs: 1618436796\n",
    "    nsecs:  55785179\n",
    "  frame_id: \"argo/left_wheel_axis\"\n",
    "data: 4\n",
    "resolution: 135\n",
    "type: 1\n",
    "---\n",
    "```    \n",
    "\n",
    "Let's look at what each field means:\n",
    "\n",
    "* `seq`: is an incremental identifier of the message. For each message received, it will increase by one. \n",
    "* `stamp`: the timestamp of the message. (Note: this field will be empty when looking at it through VNC)\n",
    "* `data`: is the cumulative count of ticks from the encoder in this instance. It will increase if the wheel is spinning forward, decrease if backwards. This is the actual measurement we can use to build our algorithms going forward.\n",
    "* `resolution`: is the total number of ticks for each full revolution of the wheel (a constant).\n",
    "* `type`: indicates the kind of encoder measurements. `1` stands for [incremental measurements](https://github.com/duckietown/dt-ros-commons/blob/daffy/packages/duckietown_msgs/msg/WheelEncoderStamped.msg). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš™ Read data from wheel encoders (physical Duckiebot)\n",
    "\n",
    "With a similar procedure, we can verify the wheel encoder data from the physical Duckiebot. \n",
    "\n",
    "Note: before starting this procedure, make sure your Duckiebot is powered on and connect to the network. You can verify this by opening the Dashboard > Robot page and assessing that everything is online, and / or `ping ROBOTNAME.local` from your computer terminal and obtain a positive response.\n",
    "\n",
    "1. Open a terminal on your computer and navigate to the `lx22-exercises/mooc-modcon/` folder. Unless you did it already (but it won't break anything if you do it again), type: \n",
    "\n",
    "       dts code build\n",
    "\n",
    "\n",
    "2. Run this activity on the robot with: (Note: The duckiebot's default password is `quackquack`.)\n",
    "\n",
    "       dts code workbench -b ROBOTNAME\n",
    "\n",
    "\n",
    "3. Find the localhost address of VNC and paste it in browser. \n",
    "\n",
    "4. Once inside VNC, open RQT image view (through the icon on the desktop) and select the \"compressed image\" topic from the dropdown menu. You should see what your robot sees.\n",
    "        \n",
    "5. Open LX terminal (always inside VNC, through the icon on the desktop) and type:\n",
    "    \n",
    "       rostopic list\n",
    "\n",
    "\n",
    "6. Find your wheel encoder topics, and visualize the messages with (e.g., for the left encoder):\n",
    "\n",
    "       rostopic echo /ROBOTNAME/left_wheel_encoder_node/tick\n",
    "\n",
    "\n",
    "7. Open the virtual joystick inside VNC and press any arrow key on your keyboard. You should see the robot moving and data streaming in the terminal. As in the simulation case, you will see the wheel encoder messages.\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/03-wheel-encoders/VNC-physical-robot-encoder.png\" width=\"500\" alt=\"rostopic-list\"></p>\n",
    "\n",
    "\n",
    "```    \n",
    "---\n",
    "header: \n",
    "  seq: 372\n",
    "  stamp: \n",
    "    secs: 1618436796\n",
    "    nsecs:  55785179\n",
    "  frame_id: \"argo/left_wheel_axis\"\n",
    "data: 4\n",
    "resolution: 135\n",
    "type: 1\n",
    "---\n",
    "```  \n",
    "\n",
    "Alternatively, you can view the encoder information directly without the need to start up VNC. You can run it through dts command on your host computer.\n",
    "\n",
    "1. Open a terminal on your computer and type:\n",
    "\n",
    "        dts start_gui_tools ROBOTNAME\n",
    "\n",
    "2. Then run:\n",
    "\n",
    "        rostopic echo /ROBOTNAME/left_wheel_encoder_node/tick\n",
    "\n",
    "You should see rostopic similar to this:\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/03-wheel-encoders/gui-tools-robot-encoder.png\" width=\"500\" alt=\"rostopic-list\"></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the number of ticks from each wheel\n",
    "\n",
    "The wheel encoder message above provides several pieces of information. Let's extract data from it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The received message is :\n",
      "\n",
      "header: \n",
      "  seq: 372\n",
      "  stamp: \n",
      "    secs: 1618436796\n",
      "    nsecs:  55785179\n",
      "  frame_id: \"agent/left_wheel_axis\"\n",
      "data: 4\n",
      "resolution: 135\n",
      "type: 1\n",
      "\n",
      "N. of ticks : 4\n",
      "Total ticks : 135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tests.unit_test.UnitTestMessage at 0x7fdd44d549d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tests.unit_test import UnitTestMessage\n",
    "\n",
    "# We define this function just to show how to extract data from the encoder_msg, which is the data coming from the wheel ecoders\n",
    "\n",
    "def EncoderCallback(encoder_msg):\n",
    "    \n",
    "    N_tot = encoder_msg.resolution # number of ticks per wheel revolution\n",
    "    ticks = encoder_msg.data # incremental count of ticks from the encoder\n",
    "    \n",
    "    #Let's see if we've done it right\n",
    "    print(\"The received message is :\")\n",
    "    print()\n",
    "    print(encoder_msg)\n",
    "    print()\n",
    "    print(f\"N. of ticks : {ticks}\")\n",
    "    print(f\"Total ticks : {N_tot}\")\n",
    "\n",
    "\n",
    "# Testing the callback\n",
    "UnitTestMessage(EncoderCallback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to read and understand wheel encoder data, and extract fields of interest from the messages. You can proceed to the next tutorial, the [odometry activity](../04-Odometry/odometry_activity.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
